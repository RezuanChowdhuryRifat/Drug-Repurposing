{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSDCws8uAQtnFg+YPph1ix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RezuanChowdhuryRifat/Drug-Repurposing/blob/main/drug_repurposing_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARS COV-2 Knowledge Graph"
      ],
      "metadata": {
        "id": "UYBtu7UggJQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load packages\n"
      ],
      "metadata": {
        "id": "Z76-0CwVgCFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3QSeH75lAk5",
        "outputId": "5e4b3ea0-527f-44bf-f3af-278b75214c88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IXmd3h_sr9em"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules import Module\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.utils import add_remaining_self_loops, add_self_loops\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_geometric.nn import GCNConv, SAGEConv,GAE, VGAE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size=128"
      ],
      "metadata": {
        "id": "rCxPqKipsVNG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMuGVolxrf9s",
        "outputId": "7859c1eb-663f-497a-ffb1-0a9a67f283b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Preprocessed files"
      ],
      "metadata": {
        "id": "OsSqOYiAgXMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pandas<2.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "UeZvPplUtI5E",
        "outputId": "c90c1096-0760-444e-901b-0afe90cd6baa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas<2.0.0\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "be48ba4e92694630ba16690b1770f7cc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/LabelEncoder_.pkl', 'rb'))\n",
        "edge_index=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/edge_index_.pkl','rb'))\n",
        "node_feature_np=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/node_feature_.pkl','rb'))"
      ],
      "metadata": {
        "id": "fX_cwf27spUz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_feature=torch.tensor(node_feature_np, dtype=torch.float)"
      ],
      "metadata": {
        "id": "7XvL4mcGstaT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "yAILFBo7swWy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr_dict={'gene-drug':0,'gene-gene':1,'bait-gene':2, 'gene-phenotype':3, 'drug-phenotype':4}\n",
        "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])"
      ],
      "metadata": {
        "id": "7jNSXhBxsy5L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index['type'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCVu_SVBs3WL",
        "outputId": "07a9d7f8-3c98-407e-9fbe-8df329cfe0c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    454738\n",
              "1      6238\n",
              "3      2190\n",
              "4      1700\n",
              "2       247\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)"
      ],
      "metadata": {
        "id": "ynCfh-wnfulP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(x=node_feature,\n",
        "            edge_index=edge.t().contiguous(),\n",
        "            edge_attr=edge_attr\n",
        "           )"
      ],
      "metadata": {
        "id": "3KR2IjP8fvSy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.num_features, data.num_nodes,data.num_edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nrbg4yLfyg8",
        "outputId": "0d7f6b49-36a5-4e61-e655-afc5e0e95fbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 21306, 465113)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG3jfPtZf04B",
        "outputId": "795c6ca0-d526-44f3-f765-057c971ac764"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([465113])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.contains_isolated_nodes(), data.is_directed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-0cwCpKf6pj",
        "outputId": "fb493814-32d7-4aed-c325-3a047a473bf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(0)"
      ],
      "metadata": {
        "id": "PMHs-CIxuOIU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch**"
      ],
      "metadata": {
        "id": "80XPpV2uggLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1):\n",
        "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
        "    into positive and negative train/val/test edges, and adds attributes of\n",
        "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
        "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
        "    to :attr:`data`.\n",
        "\n",
        "    Args:\n",
        "        data (Data): The data object.\n",
        "        val_ratio (float, optional): The ratio of positive validation\n",
        "            edges. (default: :obj:`0.05`)\n",
        "        test_ratio (float, optional): The ratio of positive test\n",
        "            edges. (default: :obj:`0.1`)\n",
        "\n",
        "    :rtype: :class:`torch_geometric.data.Data`\n",
        "    \"\"\"\n",
        "\n",
        "    assert 'batch' not in data  # No batch-mode.\n",
        "\n",
        "    num_nodes = data.num_nodes\n",
        "    row, col = data.edge_index\n",
        "    #data.edge_index = None\n",
        "    attr = data.edge_attr\n",
        "\n",
        "    # Return upper triangular portion.\n",
        "    #mask = row < col\n",
        "    #row, col = row[mask], col[mask]\n",
        "\n",
        "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
        "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
        "\n",
        "    # Positive edges.\n",
        "    perm = torch.randperm(row.size(0))\n",
        "    row, col = row[perm], col[perm]\n",
        "    attr=attr[perm]\n",
        "\n",
        "    r, c = row[:n_v], col[:n_v]\n",
        "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.val_pos_edge_attr = attr[:n_v]\n",
        "\n",
        "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
        "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.test_post_edge_attr = attr[n_v:n_v + n_t]\n",
        "\n",
        "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
        "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.train_pos_edge_attr = attr[n_v+n_t:]\n",
        "\n",
        "    # Negative edges.\n",
        "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
        "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
        "    neg_adj_mask[row, col] = 0\n",
        "\n",
        "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
        "    perm = random.sample(range(neg_row.size(0)),\n",
        "                         min(n_v + n_t, neg_row.size(0)))\n",
        "    perm = torch.tensor(perm)\n",
        "    perm = perm.to(torch.long)\n",
        "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
        "\n",
        "    neg_adj_mask[neg_row, neg_col] = 0\n",
        "    data.train_neg_adj_mask = neg_adj_mask\n",
        "\n",
        "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
        "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
        "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "7KxeESHQf7gZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbaRqqANv3g6",
        "outputId": "03a30cdc-3c04-4f0a-90a7-72bfcfe1a1ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_split=train_test_split_edges(data, test_ratio=0.1, val_ratio=0)\n",
        "x,train_pos_edge_index,train_pos_edge_attr = data_split.x.to(device), data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)"
      ],
      "metadata": {
        "id": "1xDDYVELgo6k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)"
      ],
      "metadata": {
        "id": "t7MFTFTqgy0a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(train_pos_edge_attr.cpu().numpy()).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhgqFDMug2f1",
        "outputId": "064af0ee-82d8-4db2-ec9d-da698be36311"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    409272\n",
              "1     26879\n",
              "3      1959\n",
              "4      1523\n",
              "2       224\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
      ],
      "metadata": {
        "id": "fEbIG7XKg6J3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Models"
      ],
      "metadata": {
        "id": "eUYrO-07hEcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define VGAE model"
      ],
      "metadata": {
        "id": "PrOR9bG9hKZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_VGAE(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
        "        super(Encoder_VGAE, self).__init__()\n",
        "        self.isClassificationTask=isClassificationTask\n",
        "        self.conv_gene_drug=  SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_gene_gene = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_bait_gene = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_gene_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_drug_phenotype = SAGEConv(in_channels, 2*out_channels)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(5*2*out_channels)\n",
        "        #variational encoder\n",
        "        self.conv_mu = SAGEConv(5*2*out_channels, out_channels, )\n",
        "        self.conv_logvar = SAGEConv(5*2*out_channels, out_channels,)\n",
        "\n",
        "    def forward(self,x,edge_index,edge_attr):\n",
        "\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        index_gene_drug=(edge_attr==0).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_drug=edge_index[:, index_gene_drug]\n",
        "\n",
        "        index_gene_gene=(edge_attr==1).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_gene=edge_index[:, index_gene_gene]\n",
        "\n",
        "        index_bait_gene=(edge_attr==2).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_bait_gene=edge_index[:, index_bait_gene]\n",
        "\n",
        "        index_gene_phenotype=(edge_attr==3).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_phenotype=edge_index[:, index_gene_phenotype]\n",
        "\n",
        "        index_drug_phenotype=(edge_attr==4).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_drug_phenotype=edge_index[:, index_drug_phenotype]\n",
        "\n",
        "\n",
        "        x_gene_drug = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_drug)), p=0.5, training=self.training, )\n",
        "        x_gene_gene = F.dropout(F.relu(self.conv_gene_gene(x,edge_index_gene_gene)), p=0.5, training=self.training)\n",
        "        x_bait_gene = F.dropout(F.relu(self.conv_bait_gene(x,edge_index_bait_gene)), p=0.1, training=self.training)\n",
        "        x_gene_phenotype = F.dropout(F.relu(self.conv_gene_phenotype(x,edge_index_gene_phenotype)), training=self.training)\n",
        "        x_drug_phenotype = F.dropout(F.relu(self.conv_drug_phenotype(x,edge_index_drug_phenotype)), training=self.training)\n",
        "\n",
        "        x=self.bn(torch.cat([x_gene_drug,x_gene_gene,x_bait_gene,x_gene_phenotype,x_drug_phenotype],dim=1))\n",
        "\n",
        "        return self.conv_mu(x,edge_index), self.conv_logvar(x,edge_index)"
      ],
      "metadata": {
        "id": "IHfdCDnYg6Le"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=VGAE(Encoder_VGAE(node_feature.shape[1], embedding_size)).to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "wKT6FhAohbV7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(x, train_pos_edge_index, train_pos_edge_attr)\n",
        "    loss = model.recon_loss(z, train_pos_edge_index)\n",
        "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss.item())\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z=model.encode(x, train_pos_edge_index,train_pos_edge_attr)\n",
        "    return model.test(z, pos_edge_index, neg_edge_index)"
      ],
      "metadata": {
        "id": "dh0oa0i5hd9s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DRKG's accuracy for comparison\n",
        "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZleFAHHZhhO0",
        "outputId": "ccd2cd86-848d-4f78-a244-bc65e10d9a46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3158374117754316, 0.4161200541502532)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "    train()\n",
        "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
        "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9IDUZNyhjyH",
        "outputId": "fb6ea06f-6621-4b94-90f5-2f467f8a9b0d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.534833908081055\n",
            "Epoch: 001, AUC: 0.7730, AP: 0.6805\n",
            "15.783634185791016\n",
            "Epoch: 002, AUC: 0.8101, AP: 0.7358\n",
            "16.09006690979004\n",
            "Epoch: 003, AUC: 0.7884, AP: 0.7127\n",
            "16.473175048828125\n",
            "Epoch: 004, AUC: 0.7694, AP: 0.6909\n",
            "16.178550720214844\n",
            "Epoch: 005, AUC: 0.7668, AP: 0.6879\n",
            "16.475645065307617\n",
            "Epoch: 006, AUC: 0.7835, AP: 0.7060\n",
            "15.958930015563965\n",
            "Epoch: 007, AUC: 0.7964, AP: 0.7233\n",
            "14.960944175720215\n",
            "Epoch: 008, AUC: 0.7935, AP: 0.7208\n",
            "14.432853698730469\n",
            "Epoch: 009, AUC: 0.7960, AP: 0.7292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node Embedding"
      ],
      "metadata": {
        "id": "bxmART4LhpNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
        "z_np = z.squeeze().detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "MQrR8Rvnhn4a"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=\"/content/drive/MyDrive/Drug Repurposing/\""
      ],
      "metadata": {
        "id": "RqKlhn-pxPAy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the new embedding"
      ],
      "metadata": {
        "id": "8znhE3bliHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(z_np, open(data_path+'node_embedding_'+'.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "RSCuZ8SYh8cy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the torach model"
      ],
      "metadata": {
        "id": "U94bbwTuiQqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), data_path+'VAE_encoders_'+'.pkl')"
      ],
      "metadata": {
        "id": "FF17lR0KiPAf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(data_path+'VAE_encoders_'+'.pkl'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8kn_IBioDt",
        "outputId": "46ab029f-3bfb-4009-f2d2-8d0fcf6ce14e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGAE(\n",
              "  (encoder): Encoder_VGAE(\n",
              "    (conv_gene_drug): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_gene_gene): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_bait_gene): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_gene_phenotype): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_drug_phenotype): SAGEConv(400, 256, aggr=mean)\n",
              "    (bn): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_mu): SAGEConv(1280, 128, aggr=mean)\n",
              "    (conv_logvar): SAGEConv(1280, 128, aggr=mean)\n",
              "  )\n",
              "  (decoder): InnerProductDecoder()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranking Models"
      ],
      "metadata": {
        "id": "_y-dIBVoisXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score"
      ],
      "metadata": {
        "id": "jsu_mKO2iqiE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topk=300\n",
        "types=np.array([item.split('_')[0] for item in le.classes_ ])"
      ],
      "metadata": {
        "id": "GJk22w47iybc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load drugs under clinical trial"
      ],
      "metadata": {
        "id": "g4Rqgl7_jMRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label\n",
        "trials=pd.read_excel('/content/drive/MyDrive/Drug Repurposing/All_trails_5_24.xlsx',header=1,index_col=0)\n",
        "trials_drug=set([drug.strip().upper() for lst in trials.loc[trials['study_category'].apply(lambda x: 'drug' in x.lower()),'intervention'].apply(lambda x: re.split(r'[+|/|,]',x.replace(' vs. ', '/').replace(' vs ', '/').replace(' or ', '/').replace(' with and without ', '/').replace(' /wo ', '/').replace(' /w ', '/').replace(' and ', '/').replace(' - ', '/').replace(' (', '/').replace(') ', '/'))).values for drug in lst])\n",
        "drug_labels=[1 if drug.split('_')[1] in trials_drug else 0 for drug in le.classes_[types=='drug'] ]"
      ],
      "metadata": {
        "id": "j3jNQtgSjAK3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BPR NN Loss**"
      ],
      "metadata": {
        "id": "o9q9VJWYjWLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=70\n",
        "indices = np.arange(len(drug_labels))\n",
        "X_train, X_test, y_train, y_test,indices_train,indices_test=train_test_split(z_np[types=='drug'],drug_labels,indices, test_size=0.5,random_state=seed,)"
      ],
      "metadata": {
        "id": "gKHxVIiejRKa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable wrapping for torch.tensor\n",
        "_X_train, _y_train=Variable(torch.tensor(X_train,dtype=torch.float).to(device)), Variable(torch.tensor(y_train,dtype=torch.float).to(device))\n",
        "_X_test, _y_test=Variable(torch.tensor(X_test,dtype=torch.float).to(device)), Variable(torch.tensor(y_test,dtype=torch.float).to(device))"
      ],
      "metadata": {
        "id": "SEnHLd3Ejecb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self,embedding_dim=embedding_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1=nn.Linear(embedding_dim,embedding_dim)\n",
        "        self.fc2=nn.Linear(embedding_dim,1)\n",
        "        self.bn=nn.BatchNorm1d(embedding_dim)\n",
        "    def forward(self, x):\n",
        "        residual1 = x\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x= self.bn(F.dropout(F.relu(self.fc1(x)),training=self.training))\n",
        "        x += residual1\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "QFucMU1ojg5T"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import BatchSampler, WeightedRandomSampler\n",
        "class BPRLoss(nn.Module):\n",
        "    def __init__(self, num_neg_samples):\n",
        "        super(BPRLoss, self).__init__()\n",
        "        self.num_neg_samples=num_neg_samples\n",
        "\n",
        "    def forward(self, output, label):\n",
        "        positive_output=output[label==1]\n",
        "        negative_output=output[label!=1]\n",
        "\n",
        "        #negative sample proportional to the high values\n",
        "        negative_sampler=WeightedRandomSampler(negative_output-min(negative_output), num_samples=self.num_neg_samples*len(positive_output),replacement=True)\n",
        "        negative_sample_output=negative_output[torch.tensor(list(BatchSampler(negative_sampler, batch_size=len(positive_output),drop_last=True)),dtype=torch.long).t()]\n",
        "        return -(positive_output.view(-1,1)-negative_sample_output).sigmoid().log().mean()"
      ],
      "metadata": {
        "id": "YWc292kZjjb9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=Classifier(embedding_size).to(device)\n",
        "optimizer=torch.optim.Adam(clf.parameters())\n",
        "criterion=BPRLoss(num_neg_samples=15)"
      ],
      "metadata": {
        "id": "UJjfRasMjnEa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_auprc=0\n",
        "for epoch in range(30):\n",
        "    clf.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = clf(_X_train)\n",
        "    loss=criterion(out.squeeze(), _y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print('training loss',loss.item())\n",
        "\n",
        "    clf.eval()\n",
        "    print('test loss', criterion(clf(_X_test).squeeze(), _y_test).item())\n",
        "    prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
        "    auprc=metrics.average_precision_score(y_test,prob)\n",
        "    if auprc>best_auprc:\n",
        "        best_auproc=auprc\n",
        "        torch.save(clf, data_path+'nn_clf-temp.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4RM_jRNjqQG",
        "outputId": "d3ab3d5e-24c2-4eaf-cedf-06d672b1342c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss 0.9411014318466187\n",
            "test loss 0.6586974859237671\n",
            "training loss 0.773923397064209\n",
            "test loss 0.6376845836639404\n",
            "training loss 0.7376603484153748\n",
            "test loss 0.6093034148216248\n",
            "training loss 0.6510076522827148\n",
            "test loss 0.5981817245483398\n",
            "training loss 0.5972989201545715\n",
            "test loss 0.5812066197395325\n",
            "training loss 0.5525542497634888\n",
            "test loss 0.5612711906433105\n",
            "training loss 0.541297435760498\n",
            "test loss 0.5645804405212402\n",
            "training loss 0.5235039591789246\n",
            "test loss 0.5553598403930664\n",
            "training loss 0.5751973986625671\n",
            "test loss 0.5416647791862488\n",
            "training loss 0.6030097007751465\n",
            "test loss 0.5302438735961914\n",
            "training loss 0.5759276747703552\n",
            "test loss 0.5470704436302185\n",
            "training loss 0.5769608020782471\n",
            "test loss 0.539020299911499\n",
            "training loss 0.500482439994812\n",
            "test loss 0.5379806756973267\n",
            "training loss 0.5692045092582703\n",
            "test loss 0.545048713684082\n",
            "training loss 0.5898001790046692\n",
            "test loss 0.5453366637229919\n",
            "training loss 0.5933216214179993\n",
            "test loss 0.5240334868431091\n",
            "training loss 0.5795498490333557\n",
            "test loss 0.5343819260597229\n",
            "training loss 0.585411012172699\n",
            "test loss 0.5098419785499573\n",
            "training loss 0.539105236530304\n",
            "test loss 0.5290257334709167\n",
            "training loss 0.502587080001831\n",
            "test loss 0.5114418268203735\n",
            "training loss 0.5451704263687134\n",
            "test loss 0.5271354913711548\n",
            "training loss 0.5897212624549866\n",
            "test loss 0.5338227152824402\n",
            "training loss 0.5864011645317078\n",
            "test loss 0.536204993724823\n",
            "training loss 0.5813360214233398\n",
            "test loss 0.5245136022567749\n",
            "training loss 0.5003993511199951\n",
            "test loss 0.5200497508049011\n",
            "training loss 0.546786904335022\n",
            "test loss 0.510426938533783\n",
            "training loss 0.5253490805625916\n",
            "test loss 0.5133043527603149\n",
            "training loss 0.5870693922042847\n",
            "test loss 0.5160320401191711\n",
            "training loss 0.537607729434967\n",
            "test loss 0.5084456205368042\n",
            "training loss 0.5269591808319092\n",
            "test loss 0.515533983707428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.load_state_dict(torch.load('/content/drive/MyDrive/Drug Repurposing/nn_clf-temp.pt').state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8462XMbjs4V",
        "outputId": "7d660a23-c664-4bbb-bb49-ec13d08e8d63"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute AUC\n",
        "clf.eval()\n",
        "\n",
        "prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
        "print(\"AUROC\", metrics.roc_auc_score(y_test,prob))\n",
        "print(\"AUPRC\", metrics.average_precision_score(y_test,prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmF35-K2jzII",
        "outputId": "6d40c35c-2b7c-4622-d62e-acec0fd5f1cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC 0.8241590050982317\n",
            "AUPRC 0.17270869098996086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_items_idx=np.argsort(-clf(torch.tensor(z_np[types=='drug'],dtype=torch.float).to(device)).squeeze().detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "xSN0i9Dlj2eu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model**"
      ],
      "metadata": {
        "id": "eDp8wY-sj8IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=LogisticRegression().fit(X_train,y_train)\n",
        "print(\"Logit AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"Logit AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvnLbhhQj5jq",
        "outputId": "4ae6a1df-b927-4f83-c047-1a51dc28f11f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logit AUROC 0.8497808187034707\n",
            "Logit AUPRC 0.20527540655985937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=GradientBoostingClassifier().fit(X_train,y_train)\n",
        "print(\"XGBoost AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"XGBoost AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a43ixSzMkJrw",
        "outputId": "7b8261c5-daf9-479a-9b34-2cd43461e5fc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUROC 0.8394430341944155\n",
            "XGBoost AUPRC 0.12458640243400262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=RandomForestClassifier().fit(X_train,y_train)\n",
        "print(\"rf AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"rf AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI3yN3nbkMxH",
        "outputId": "d8fe0c8d-5d0e-44ea-e72f-2920c16baddf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf AUROC 0.8487889033469143\n",
            "rf AUPRC 0.11654738877075906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=make_pipeline(StandardScaler(), SVC(gamma='auto',probability=True)).fit(X_train,y_train)\n",
        "print(\"svm AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"svm AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfEZ9jTNkQzh",
        "outputId": "99dcc955-929f-44cd-d9f6-4c8af76aa805"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm AUROC 0.7398981953539965\n",
            "svm AUPRC 0.15403532839974704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_drugs=pd.DataFrame([(rank, drug.split('_')[1]) for rank,drug in enumerate(le.inverse_transform((types=='drug').nonzero()[0][top_items_idx])[:topk+1])], columns=['rank', 'drug'])\n",
        "topk_drugs['under_trials']=topk_drugs['drug'].isin(trials_drug).astype(int)\n",
        "topk_drugs['is_used_in_training']=topk_drugs['drug'].isin(np.array([drug.split('_')[1] for drug in le.classes_[types=='drug']])[indices_train]).astype(int)\n",
        "topk_drugs.to_csv('top300_drugs.csv')"
      ],
      "metadata": {
        "id": "4Iai-4WLkTn8"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}