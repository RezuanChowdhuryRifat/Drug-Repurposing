{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIs1J6kWbQRtFoHtkpBC4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RezuanChowdhuryRifat/Drug-Repurposing/blob/main/drug_repurposing_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARS COV-2 Knowledge Graph"
      ],
      "metadata": {
        "id": "UYBtu7UggJQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load packages\n"
      ],
      "metadata": {
        "id": "Z76-0CwVgCFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3QSeH75lAk5",
        "outputId": "41dff4ec-f932-4599-9860-57039be275cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IXmd3h_sr9em"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules import Module\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.utils import add_remaining_self_loops, add_self_loops\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_geometric.nn import GCNConv, SAGEConv,GAE, VGAE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size=128"
      ],
      "metadata": {
        "id": "rCxPqKipsVNG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMuGVolxrf9s",
        "outputId": "491b2366-b784-4084-e2a0-208d610c5f45"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Preprocessed files"
      ],
      "metadata": {
        "id": "OsSqOYiAgXMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pandas<2.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeZvPplUtI5E",
        "outputId": "81be3d7f-f603-4d70-ebb6-9830843cfd82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas<2.0.0\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/LabelEncoder_v2.pkl', 'rb'))\n",
        "edge_index=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/edge_index_v2.pkl','rb'))\n",
        "node_feature_np=pickle.load(open('/content/drive/MyDrive/Drug Repurposing/node_feature_v2.pkl','rb'))"
      ],
      "metadata": {
        "id": "fX_cwf27spUz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_feature=torch.tensor(node_feature_np, dtype=torch.float)"
      ],
      "metadata": {
        "id": "7XvL4mcGstaT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "yAILFBo7swWy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr_dict={'gene-drug':0,'gene-gene':1,'bait-gene':2, 'gene-phenotype':3, 'drug-phenotype':4}\n",
        "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])"
      ],
      "metadata": {
        "id": "7jNSXhBxsy5L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index['type'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCVu_SVBs3WL",
        "outputId": "2c84795e-51cf-4ddc-8020-a84b39502e01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    419671\n",
              "1      6240\n",
              "3      2190\n",
              "4      1700\n",
              "2       247\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)"
      ],
      "metadata": {
        "id": "ynCfh-wnfulP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(x=node_feature,\n",
        "            edge_index=edge.t().contiguous(),\n",
        "            edge_attr=edge_attr\n",
        "           )"
      ],
      "metadata": {
        "id": "3KR2IjP8fvSy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.num_features, data.num_nodes,data.num_edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nrbg4yLfyg8",
        "outputId": "848938eb-37c3-46d4-efbc-e827866894d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 14675, 430048)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG3jfPtZf04B",
        "outputId": "c178df79-2064-42e1-c838-45f250006115"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([430048])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.contains_isolated_nodes(), data.is_directed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-0cwCpKf6pj",
        "outputId": "f887f640-ed56-424d-bda5-f59c41d7f5ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(0)"
      ],
      "metadata": {
        "id": "PMHs-CIxuOIU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch**"
      ],
      "metadata": {
        "id": "80XPpV2uggLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1):\n",
        "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
        "    into positive and negative train/val/test edges, and adds attributes of\n",
        "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
        "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
        "    to :attr:`data`.\n",
        "\n",
        "    Args:\n",
        "        data (Data): The data object.\n",
        "        val_ratio (float, optional): The ratio of positive validation\n",
        "            edges. (default: :obj:`0.05`)\n",
        "        test_ratio (float, optional): The ratio of positive test\n",
        "            edges. (default: :obj:`0.1`)\n",
        "\n",
        "    :rtype: :class:`torch_geometric.data.Data`\n",
        "    \"\"\"\n",
        "\n",
        "    assert 'batch' not in data  # No batch-mode.\n",
        "\n",
        "    num_nodes = data.num_nodes\n",
        "    row, col = data.edge_index\n",
        "    #data.edge_index = None\n",
        "    attr = data.edge_attr\n",
        "\n",
        "    # Return upper triangular portion.\n",
        "    #mask = row < col\n",
        "    #row, col = row[mask], col[mask]\n",
        "\n",
        "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
        "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
        "\n",
        "    # Positive edges.\n",
        "    perm = torch.randperm(row.size(0))\n",
        "    row, col = row[perm], col[perm]\n",
        "    attr=attr[perm]\n",
        "\n",
        "    r, c = row[:n_v], col[:n_v]\n",
        "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.val_pos_edge_attr = attr[:n_v]\n",
        "\n",
        "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
        "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.test_post_edge_attr = attr[n_v:n_v + n_t]\n",
        "\n",
        "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
        "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
        "    data.train_pos_edge_attr = attr[n_v+n_t:]\n",
        "\n",
        "    # Negative edges.\n",
        "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
        "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
        "    neg_adj_mask[row, col] = 0\n",
        "\n",
        "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
        "    perm = random.sample(range(neg_row.size(0)),\n",
        "                         min(n_v + n_t, neg_row.size(0)))\n",
        "    perm = torch.tensor(perm)\n",
        "    perm = perm.to(torch.long)\n",
        "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
        "\n",
        "    neg_adj_mask[neg_row, neg_col] = 0\n",
        "    data.train_neg_adj_mask = neg_adj_mask\n",
        "\n",
        "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
        "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
        "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "7KxeESHQf7gZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbaRqqANv3g6",
        "outputId": "6d2c2c2b-b19c-4bfe-8eb6-c9e2a7e27df1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_split=train_test_split_edges(data, test_ratio=0.1, val_ratio=0)\n",
        "x,train_pos_edge_index,train_pos_edge_attr = data_split.x.to(device), data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)"
      ],
      "metadata": {
        "id": "1xDDYVELgo6k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)"
      ],
      "metadata": {
        "id": "t7MFTFTqgy0a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(train_pos_edge_attr.cpu().numpy()).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhgqFDMug2f1",
        "outputId": "6637beff-fdf0-4b1d-80b7-39d4be88461d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    377697\n",
              "1     20242\n",
              "3      1973\n",
              "4      1538\n",
              "2       220\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
      ],
      "metadata": {
        "id": "fEbIG7XKg6J3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Models"
      ],
      "metadata": {
        "id": "eUYrO-07hEcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define VGAE model"
      ],
      "metadata": {
        "id": "PrOR9bG9hKZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_VGAE(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
        "        super(Encoder_VGAE, self).__init__()\n",
        "        self.isClassificationTask=isClassificationTask\n",
        "        self.conv_gene_drug=  SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_gene_gene = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_bait_gene = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_gene_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
        "        self.conv_drug_phenotype = SAGEConv(in_channels, 2*out_channels)\n",
        "\n",
        "        self.bn = nn.BatchNorm1d(5*2*out_channels)\n",
        "        #variational encoder\n",
        "        self.conv_mu = SAGEConv(5*2*out_channels, out_channels, )\n",
        "        self.conv_logvar = SAGEConv(5*2*out_channels, out_channels,)\n",
        "\n",
        "    def forward(self,x,edge_index,edge_attr):\n",
        "\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        index_gene_drug=(edge_attr==0).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_drug=edge_index[:, index_gene_drug]\n",
        "\n",
        "        index_gene_gene=(edge_attr==1).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_gene=edge_index[:, index_gene_gene]\n",
        "\n",
        "        index_bait_gene=(edge_attr==2).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_bait_gene=edge_index[:, index_bait_gene]\n",
        "\n",
        "        index_gene_phenotype=(edge_attr==3).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_gene_phenotype=edge_index[:, index_gene_phenotype]\n",
        "\n",
        "        index_drug_phenotype=(edge_attr==4).nonzero().reshape(1,-1)[0]\n",
        "        edge_index_drug_phenotype=edge_index[:, index_drug_phenotype]\n",
        "\n",
        "\n",
        "        x_gene_drug = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_drug)), p=0.5, training=self.training, )\n",
        "        x_gene_gene = F.dropout(F.relu(self.conv_gene_gene(x,edge_index_gene_gene)), p=0.5, training=self.training)\n",
        "        x_bait_gene = F.dropout(F.relu(self.conv_bait_gene(x,edge_index_bait_gene)), p=0.1, training=self.training)\n",
        "        x_gene_phenotype = F.dropout(F.relu(self.conv_gene_phenotype(x,edge_index_gene_phenotype)), training=self.training)\n",
        "        x_drug_phenotype = F.dropout(F.relu(self.conv_drug_phenotype(x,edge_index_drug_phenotype)), training=self.training)\n",
        "\n",
        "        x=self.bn(torch.cat([x_gene_drug,x_gene_gene,x_bait_gene,x_gene_phenotype,x_drug_phenotype],dim=1))\n",
        "\n",
        "        return self.conv_mu(x,edge_index), self.conv_logvar(x,edge_index)"
      ],
      "metadata": {
        "id": "IHfdCDnYg6Le"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=VGAE(Encoder_VGAE(node_feature.shape[1], embedding_size)).to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "wKT6FhAohbV7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(x, train_pos_edge_index, train_pos_edge_attr)\n",
        "    loss = model.recon_loss(z, train_pos_edge_index)\n",
        "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss.item())\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z=model.encode(x, train_pos_edge_index,train_pos_edge_attr)\n",
        "    return model.test(z, pos_edge_index, neg_edge_index)"
      ],
      "metadata": {
        "id": "dh0oa0i5hd9s"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DRKG's accuracy for comparison\n",
        "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZleFAHHZhhO0",
        "outputId": "03b4ba61-fc13-42c4-bb47-adefad719708"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2965669438757359, 0.4280773528040785)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "    train()\n",
        "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
        "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9IDUZNyhjyH",
        "outputId": "3ff55bd7-35d6-49d2-f85d-1ac505ac7a7b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.258056640625\n",
            "Epoch: 001, AUC: 0.6249, AP: 0.5177\n",
            "18.37226676940918\n",
            "Epoch: 002, AUC: 0.7667, AP: 0.6993\n",
            "15.807873725891113\n",
            "Epoch: 003, AUC: 0.7267, AP: 0.6480\n",
            "15.341449737548828\n",
            "Epoch: 004, AUC: 0.6923, AP: 0.6173\n",
            "16.169008255004883\n",
            "Epoch: 005, AUC: 0.7188, AP: 0.6450\n",
            "15.32749080657959\n",
            "Epoch: 006, AUC: 0.7603, AP: 0.6967\n",
            "14.353047370910645\n",
            "Epoch: 007, AUC: 0.8016, AP: 0.7688\n",
            "13.345233917236328\n",
            "Epoch: 008, AUC: 0.8206, AP: 0.7901\n",
            "12.078516006469727\n",
            "Epoch: 009, AUC: 0.8326, AP: 0.7885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node Embedding"
      ],
      "metadata": {
        "id": "bxmART4LhpNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
        "z_np = z.squeeze().detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "MQrR8Rvnhn4a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=\"/content/drive/MyDrive/Drug Repurposing/\""
      ],
      "metadata": {
        "id": "RqKlhn-pxPAy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the new embedding"
      ],
      "metadata": {
        "id": "8znhE3bliHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(z_np, open(data_path+'node_embedding_v2'+'.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "RSCuZ8SYh8cy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the torach model"
      ],
      "metadata": {
        "id": "U94bbwTuiQqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), data_path+'VAE_encoders_v2'+'.pkl')"
      ],
      "metadata": {
        "id": "FF17lR0KiPAf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(data_path+'VAE_encoders_v2'+'.pkl'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8kn_IBioDt",
        "outputId": "7cbd4e75-af61-4a4c-cb07-2d982c666f93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGAE(\n",
              "  (encoder): Encoder_VGAE(\n",
              "    (conv_gene_drug): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_gene_gene): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_bait_gene): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_gene_phenotype): SAGEConv(400, 256, aggr=mean)\n",
              "    (conv_drug_phenotype): SAGEConv(400, 256, aggr=mean)\n",
              "    (bn): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_mu): SAGEConv(1280, 128, aggr=mean)\n",
              "    (conv_logvar): SAGEConv(1280, 128, aggr=mean)\n",
              "  )\n",
              "  (decoder): InnerProductDecoder()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranking Models"
      ],
      "metadata": {
        "id": "_y-dIBVoisXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score"
      ],
      "metadata": {
        "id": "jsu_mKO2iqiE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topk=300\n",
        "types=np.array([item.split('_')[0] for item in le.classes_ ])"
      ],
      "metadata": {
        "id": "GJk22w47iybc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load drugs under clinical trial"
      ],
      "metadata": {
        "id": "g4Rqgl7_jMRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label\n",
        "trials=pd.read_excel('/content/drive/MyDrive/Drug Repurposing/All_trails_5_24.xlsx',header=1,index_col=0)\n",
        "trials_drug=set([drug.strip().upper() for lst in trials.loc[trials['study_category'].apply(lambda x: 'drug' in x.lower()),'intervention'].apply(lambda x: re.split(r'[+|/|,]',x.replace(' vs. ', '/').replace(' vs ', '/').replace(' or ', '/').replace(' with and without ', '/').replace(' /wo ', '/').replace(' /w ', '/').replace(' and ', '/').replace(' - ', '/').replace(' (', '/').replace(') ', '/'))).values for drug in lst])\n",
        "drug_labels=[1 if drug.split('_')[1] in trials_drug else 0 for drug in le.classes_[types=='drug'] ]"
      ],
      "metadata": {
        "id": "j3jNQtgSjAK3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BPR NN Loss**"
      ],
      "metadata": {
        "id": "o9q9VJWYjWLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=70\n",
        "indices = np.arange(len(drug_labels))\n",
        "X_train, X_test, y_train, y_test,indices_train,indices_test=train_test_split(z_np[types=='drug'],drug_labels,indices, test_size=0.5,random_state=seed,)"
      ],
      "metadata": {
        "id": "gKHxVIiejRKa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable wrapping for torch.tensor\n",
        "_X_train, _y_train=Variable(torch.tensor(X_train,dtype=torch.float).to(device)), Variable(torch.tensor(y_train,dtype=torch.float).to(device))\n",
        "_X_test, _y_test=Variable(torch.tensor(X_test,dtype=torch.float).to(device)), Variable(torch.tensor(y_test,dtype=torch.float).to(device))"
      ],
      "metadata": {
        "id": "SEnHLd3Ejecb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self,embedding_dim=embedding_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1=nn.Linear(embedding_dim,embedding_dim)\n",
        "        self.fc2=nn.Linear(embedding_dim,1)\n",
        "        self.bn=nn.BatchNorm1d(embedding_dim)\n",
        "    def forward(self, x):\n",
        "        residual1 = x\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x= self.bn(F.dropout(F.relu(self.fc1(x)),training=self.training))\n",
        "        x += residual1\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "QFucMU1ojg5T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import BatchSampler, WeightedRandomSampler\n",
        "class BPRLoss(nn.Module):\n",
        "    def __init__(self, num_neg_samples):\n",
        "        super(BPRLoss, self).__init__()\n",
        "        self.num_neg_samples=num_neg_samples\n",
        "\n",
        "    def forward(self, output, label):\n",
        "        positive_output=output[label==1]\n",
        "        negative_output=output[label!=1]\n",
        "\n",
        "        #negative sample proportional to the high values\n",
        "        negative_sampler=WeightedRandomSampler(negative_output-min(negative_output), num_samples=self.num_neg_samples*len(positive_output),replacement=True)\n",
        "        negative_sample_output=negative_output[torch.tensor(list(BatchSampler(negative_sampler, batch_size=len(positive_output),drop_last=True)),dtype=torch.long).t()]\n",
        "        return -(positive_output.view(-1,1)-negative_sample_output).sigmoid().log().mean()"
      ],
      "metadata": {
        "id": "YWc292kZjjb9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf=Classifier(embedding_size).to(device)\n",
        "optimizer=torch.optim.Adam(clf.parameters())\n",
        "criterion=BPRLoss(num_neg_samples=15)"
      ],
      "metadata": {
        "id": "UJjfRasMjnEa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_auprc=0\n",
        "for epoch in range(30):\n",
        "    clf.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = clf(_X_train)\n",
        "    loss=criterion(out.squeeze(), _y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print('training loss',loss.item())\n",
        "\n",
        "    clf.eval()\n",
        "    print('test loss', criterion(clf(_X_test).squeeze(), _y_test).item())\n",
        "    prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
        "    auprc=metrics.average_precision_score(y_test,prob)\n",
        "    if auprc>best_auprc:\n",
        "        best_auproc=auprc\n",
        "        torch.save(clf, data_path+'nn_clf-temp_v2.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4RM_jRNjqQG",
        "outputId": "f12f8d6a-3406-47c0-92b4-a7b9d29e029e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss 0.42777496576309204\n",
            "test loss 0.3844509422779083\n",
            "training loss 0.44530823826789856\n",
            "test loss 0.405448853969574\n",
            "training loss 0.3897322118282318\n",
            "test loss 0.3849104344844818\n",
            "training loss 0.4157465994358063\n",
            "test loss 0.39715251326560974\n",
            "training loss 0.39845943450927734\n",
            "test loss 0.3831035792827606\n",
            "training loss 0.3549855947494507\n",
            "test loss 0.36529678106307983\n",
            "training loss 0.40289604663848877\n",
            "test loss 0.3786458373069763\n",
            "training loss 0.3604772686958313\n",
            "test loss 0.37360137701034546\n",
            "training loss 0.4170481860637665\n",
            "test loss 0.3718845546245575\n",
            "training loss 0.5033170580863953\n",
            "test loss 0.3902912735939026\n",
            "training loss 0.39711833000183105\n",
            "test loss 0.3668919503688812\n",
            "training loss 0.3956127166748047\n",
            "test loss 0.3674808740615845\n",
            "training loss 0.4476303458213806\n",
            "test loss 0.37228211760520935\n",
            "training loss 0.4190622866153717\n",
            "test loss 0.36150938272476196\n",
            "training loss 0.40032827854156494\n",
            "test loss 0.37298762798309326\n",
            "training loss 0.40773171186447144\n",
            "test loss 0.37982821464538574\n",
            "training loss 0.3535864055156708\n",
            "test loss 0.3742724657058716\n",
            "training loss 0.4289906919002533\n",
            "test loss 0.36085546016693115\n",
            "training loss 0.3839706778526306\n",
            "test loss 0.376230925321579\n",
            "training loss 0.3747375011444092\n",
            "test loss 0.38876473903656006\n",
            "training loss 0.415153831243515\n",
            "test loss 0.3923642039299011\n",
            "training loss 0.4149772822856903\n",
            "test loss 0.3620988726615906\n",
            "training loss 0.3795258104801178\n",
            "test loss 0.3518352806568146\n",
            "training loss 0.35862496495246887\n",
            "test loss 0.3860664963722229\n",
            "training loss 0.36348792910575867\n",
            "test loss 0.3555847704410553\n",
            "training loss 0.3749496042728424\n",
            "test loss 0.365780770778656\n",
            "training loss 0.3957560360431671\n",
            "test loss 0.35995280742645264\n",
            "training loss 0.37212812900543213\n",
            "test loss 0.3674183189868927\n",
            "training loss 0.35657045245170593\n",
            "test loss 0.38226205110549927\n",
            "training loss 0.41612082719802856\n",
            "test loss 0.3740920126438141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.load_state_dict(torch.load('/content/drive/MyDrive/Drug Repurposing/nn_clf-temp_v2.pt').state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8462XMbjs4V",
        "outputId": "f119cbbf-249d-44be-ed14-b09769fd384c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute AUC\n",
        "clf.eval()\n",
        "\n",
        "prob=torch.sigmoid(clf(_X_test)).cpu().detach().numpy().squeeze()\n",
        "print(\"AUROC\", metrics.roc_auc_score(y_test,prob))\n",
        "print(\"AUPRC\", metrics.average_precision_score(y_test,prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmF35-K2jzII",
        "outputId": "3d85d1df-310a-4675-cf4d-4af20cf6215b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC 0.8753525098702764\n",
            "AUPRC 0.2137688504624097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_items_idx=np.argsort(-clf(torch.tensor(z_np[types=='drug'],dtype=torch.float).to(device)).squeeze().detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "xSN0i9Dlj2eu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model**"
      ],
      "metadata": {
        "id": "eDp8wY-sj8IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=LogisticRegression().fit(X_train,y_train)\n",
        "print(\"Logit AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"Logit AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvnLbhhQj5jq",
        "outputId": "21d38ce5-acbc-414e-eff9-0772705de779"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logit AUROC 0.8701738194123981\n",
            "Logit AUPRC 0.21033463554996845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=GradientBoostingClassifier().fit(X_train,y_train)\n",
        "print(\"XGBoost AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"XGBoost AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a43ixSzMkJrw",
        "outputId": "3e2440d0-5252-4473-b87d-4cc8e0f63dd4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUROC 0.8595344306004205\n",
            "XGBoost AUPRC 0.11860170708989237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=RandomForestClassifier().fit(X_train,y_train)\n",
        "print(\"rf AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"rf AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI3yN3nbkMxH",
        "outputId": "85a70b3d-7411-4c93-d39d-39bcf9e25a81"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf AUROC 0.8369225247397837\n",
            "rf AUPRC 0.12084156255218911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=make_pipeline(StandardScaler(), SVC(gamma='auto',probability=True)).fit(X_train,y_train)\n",
        "print(\"svm AUROC\", roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))\n",
        "print(\"svm AUPRC\", average_precision_score(y_test,clf.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfEZ9jTNkQzh",
        "outputId": "fbeaccd5-d38e-4487-e806-8ade12dff1ad"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm AUROC 0.8029739014510587\n",
            "svm AUPRC 0.16606332180221894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_drugs=pd.DataFrame([(rank, drug.split('_')[1]) for rank,drug in enumerate(le.inverse_transform((types=='drug').nonzero()[0][top_items_idx])[:topk+1])], columns=['rank', 'drug'])\n",
        "topk_drugs['under_trials']=topk_drugs['drug'].isin(trials_drug).astype(int)\n",
        "topk_drugs['is_used_in_training']=topk_drugs['drug'].isin(np.array([drug.split('_')[1] for drug in le.classes_[types=='drug']])[indices_train]).astype(int)\n",
        "topk_drugs.to_csv('top300_drugs_v2.csv')"
      ],
      "metadata": {
        "id": "4Iai-4WLkTn8"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}